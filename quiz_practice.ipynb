{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bba7047",
   "metadata": {},
   "source": [
    "## Question1\n",
    "- Using the requests library, send a GET request to a specified URL.\n",
    "- Print the response headers.\n",
    "- Determine if the content is CSV or XLSX based on the Content-Type header.\n",
    "- Load the content into a pandas DataFrame:\n",
    "- Utilize io.BytesIO to create a buffer from r.content.\n",
    "- Employ either read_csv or read_excel accordingly.\n",
    "- Demonstrate the usage of r.headers, r.content, and the buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215637b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = \"REPLACE_WITH_DATA_URL\"\n",
    "r = requests.get(url, timeout=30)\n",
    "print(r.headers)\n",
    "ct = r.headers.get(\"Content-Type\", \"\").lower()\n",
    "buf = io.BytesIO(r.content)\n",
    "\n",
    "if \"csv\" in ct or ct.startswith(\"text/\"):\n",
    "    # If needed, decode and use StringIO\n",
    "    text = r.content.decode(\"utf-8\", errors=\"ignore\")\n",
    "    df = pd.read_csv(io.StringIO(text))\n",
    "else:\n",
    "    # Many data portals serve Excel as application/octet-stream\n",
    "    df = pd.read_excel(buf)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62253c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'example_url'\n",
    "headers = 'example_header'\n",
    "payload = {'key':'value'}\n",
    "r = requests.get(url,header = headers, param = payload)\n",
    "print(r.headers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b653148",
   "metadata": {},
   "source": [
    "## Question2\n",
    "Using requests, pypdf, and io.BytesIO, extract and return a list of dictionaries, each containing the page number and text, for all pages from a PDF URL that include the word “anchovies” (case-insensitive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9600f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"REPLACE_WITH_PDF_URL\"\n",
    "pdf_data = io.BytesIO(requests.get(url, timeout=30).content)\n",
    "reader = PdfReader(pdf_data)\n",
    "out = []\n",
    "for i, page in enumerate(reader.pages, start=1):\n",
    "    text = (page.extract_text() or \"\").lower()\n",
    "    if \"anchovies\" in text:\n",
    "        out.append({i: text})\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13434176",
   "metadata": {},
   "source": [
    "## Question3\n",
    "- To read a private XLSX file named \"fish\" from Google Cloud Storage (GCS) into a DataFrame using a service account key, follow these steps:\n",
    "- Retrieve GCP_SERVICE_ACCOUNT_KEY, GCP_PROJECT_ID, and GCP_BUCKET_NAME from your .env file.\n",
    "- Authenticate using google.oauth2.service_account and google.cloud.storage.\n",
    "- Download the file's bytes.\n",
    "- Load the \"fish\" sheet into a pandas DataFrame using pandas.read_excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228e169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import storage\n",
    "\n",
    "load_dotenv()\n",
    "key_path = os.getenv(\"GCP_SERVICE_ACCOUNT_KEY\")\n",
    "project = os.getenv(\"GCP_PROJECT_ID\")\n",
    "bucket_name = os.getenv(\"GCP_BUCKET_NAME\")\n",
    "blob_name = \"2020-09-11_microparticledata.xlsx\"\n",
    "\n",
    "creds = service_account.Credentials.from_service_account_file(key_path)\n",
    "client = storage.Client(project=project, credentials=creds)\n",
    "blob = client.bucket(bucket_name).blob(blob_name)\n",
    "data = blob.download_as_bytes()\n",
    "df = pd.read_excel(io.BytesIO(data), sheet_name=\"fish\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686cdb71",
   "metadata": {},
   "source": [
    "## Question4\n",
    "Generate a list of 100 random integers, convert it to bytes using pickle, and upload the resulting ex02.pickle file to GCS. Ensure the same service account authentication flow is used for the upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb3aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import storage\n",
    "\n",
    "load_dotenv()\n",
    "key_path = os.getenv(\"GCP_SERVICE_ACCOUNT_KEY\")\n",
    "project = os.getenv(\"GCP_PROJECT_ID\")\n",
    "bucket_name = os.getenv(\"GCP_BUCKET_NAME\")\n",
    "blob_name = \"2020-09-11_microparticledata.xlsx\"\n",
    "\n",
    "creds = service_account.Credentials.from_service_account_file(key_path)\n",
    "client = storage.Client(project=project, credentials=creds)\n",
    "blob = client.bucket(bucket_name).blob(blob_name)\n",
    "data = blob.download_as_bytes()\n",
    "df = pd.read_excel(io.BytesIO(data), sheet_name=\"fish\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbdfc75",
   "metadata": {},
   "source": [
    "\n",
    "## Question5\n",
    "Develop a Git workflow that includes creating a feature/search branch, making a single commit, merging it into main, performing an initial push with an upstream branch, and finally deleting the remote branch. (No actual repository execution is necessary.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c7c50e",
   "metadata": {},
   "source": [
    "git branch feature/search\n",
    "git checkout feature/search\n",
    "# ... make changes ...\n",
    "git add .\n",
    "git commit -m \"feat: add search example\"\n",
    "git checkout main\n",
    "git merge feature/search\n",
    "git push -u origin feature/search\n",
    "git push origin --delete feature/search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02f3002",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msds692",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
